{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGXI5baG0bY2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "import h5py, json\n",
        "import os,time,sys\n",
        "import math, random\n",
        "\n",
        "from importlib import reload\n",
        "\n",
        "\n",
        "run_dir = '.'\n",
        "\n",
        "pd.set_option('display.max_rows',200)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "from collections.abc import Iterable\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import pandas as pd\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# show_images\n",
        "# -------------------------------------------------------------\n",
        "#\n",
        "def plot_images(x,y=None, indices='all', columns=12, x_size=1, y_size=1,\n",
        "                colorbar=False, y_pred=None, cm='binary', norm=None, y_padding=0.35, spines_alpha=1,\n",
        "                fontsize=20, interpolation='lanczos', save_as='auto'):\n",
        "    \"\"\"\n",
        "    Show some images in a grid, with legends\n",
        "    args:\n",
        "        x             : images - Shapes must be (-1,lx,ly) (-1,lx,ly,1) or (-1,lx,ly,3)\n",
        "        y             : real classes or labels or None (None)\n",
        "        indices       : indices of images to show or 'all' for all ('all')\n",
        "        columns       : number of columns (12)\n",
        "        x_size,y_size : figure size (1), (1)\n",
        "        colorbar      : show colorbar (False)\n",
        "        y_pred        : predicted classes (None)\n",
        "        cm            : Matplotlib color map (binary)\n",
        "        norm          : Matplotlib imshow normalization (None)\n",
        "        y_padding     : Padding / rows (0.35)\n",
        "        spines_alpha  : Spines alpha (1.)\n",
        "        font_size     : Font size in px (20)\n",
        "        save_as       : Filename to use if save figs is enable ('auto')\n",
        "    returns: \n",
        "        nothing\n",
        "    \"\"\"\n",
        "    if indices=='all': indices=range(len(x))\n",
        "    if norm and len(norm) == 2: norm = matplotlib.colors.Normalize(vmin=norm[0], vmax=norm[1])\n",
        "    draw_labels = (y is not None)\n",
        "    draw_pred   = (y_pred is not None)\n",
        "    rows        = math.ceil(len(indices)/columns)\n",
        "    fig=plt.figure(figsize=(columns*x_size, rows*(y_size+y_padding)))\n",
        "    n=1\n",
        "    for i in indices:\n",
        "        axs=fig.add_subplot(rows, columns, n)\n",
        "        n+=1\n",
        "        # ---- Shape is (lx,ly)\n",
        "        if len(x[i].shape)==2:\n",
        "            xx=x[i]\n",
        "        # ---- Shape is (lx,ly,n)\n",
        "        if len(x[i].shape)==3:\n",
        "            (lx,ly,lz)=x[i].shape\n",
        "            if lz==1: \n",
        "                xx=x[i].reshape(lx,ly)\n",
        "            else:\n",
        "                xx=x[i]\n",
        "        img=axs.imshow(xx,   cmap = cm, norm=norm, interpolation=interpolation)\n",
        "#         img=axs.imshow(xx,   cmap = cm, interpolation=interpolation)\n",
        "        axs.spines['right'].set_visible(True)\n",
        "        axs.spines['left'].set_visible(True)\n",
        "        axs.spines['top'].set_visible(True)\n",
        "        axs.spines['bottom'].set_visible(True)\n",
        "        axs.spines['right'].set_alpha(spines_alpha)\n",
        "        axs.spines['left'].set_alpha(spines_alpha)\n",
        "        axs.spines['top'].set_alpha(spines_alpha)\n",
        "        axs.spines['bottom'].set_alpha(spines_alpha)\n",
        "        axs.set_yticks([])\n",
        "        axs.set_xticks([])\n",
        "        if draw_labels and not draw_pred:\n",
        "            axs.set_xlabel(y[i],fontsize=fontsize)\n",
        "        if draw_labels and draw_pred:\n",
        "            if y[i]!=y_pred[i]:\n",
        "                axs.set_xlabel(f'{y_pred[i]} ({y[i]})',fontsize=fontsize)\n",
        "                axs.xaxis.label.set_color('red')\n",
        "            else:\n",
        "                axs.set_xlabel(y[i],fontsize=fontsize)\n",
        "        if colorbar:\n",
        "            fig.colorbar(img,orientation=\"vertical\", shrink=0.65)\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "def plot_image(x,cm='binary', figsize=(4,4),interpolation='lanczos', save_as='auto'):\n",
        "    \"\"\"\n",
        "    Draw a single image.\n",
        "    Image shape can be (lx,ly), (lx,ly,1) or (lx,ly,n)\n",
        "    args:\n",
        "        x       : image as np array\n",
        "        cm      : color map ('binary')\n",
        "        figsize : fig size (4,4)\n",
        "    \"\"\"\n",
        "    # ---- Shape is (lx,ly)\n",
        "    if len(x.shape)==2:\n",
        "        xx=x\n",
        "    # ---- Shape is (lx,ly,n)\n",
        "    if len(x.shape)==3:\n",
        "        (lx,ly,lz)=x.shape\n",
        "        if lz==1: \n",
        "            xx=x.reshape(lx,ly)\n",
        "        else:\n",
        "            xx=x\n",
        "    # ---- Draw it\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.imshow(xx,   cmap = cm, interpolation=interpolation)\n",
        "    plt.show()\n",
        "\n",
        "def plot_history(history, figsize=(8,6), \n",
        "                 plot={\"Accuracy\":['accuracy','val_accuracy'], 'Loss':['loss', 'val_loss']},\n",
        "                 save_as='auto'):\n",
        "    \"\"\"\n",
        "    Show history\n",
        "    args:\n",
        "        history: history\n",
        "        figsize: fig size\n",
        "        plot: list of data to plot : {<title>:[<metrics>,...], ...}\n",
        "    \"\"\"\n",
        "    fig_id=0\n",
        "    for title,curves in plot.items():\n",
        "        plt.figure(figsize=figsize)\n",
        "        plt.title(title)\n",
        "        plt.ylabel(title)\n",
        "        plt.xlabel('Epoch')\n",
        "        for c in curves:\n",
        "            plt.plot(history.history[c])\n",
        "        plt.legend(curves, loc='upper left')\n",
        "        if save_as=='auto':\n",
        "            figname='auto'\n",
        "        else:\n",
        "            figname=f'{save_as}_{fig_id}'\n",
        "            fig_id+=1\n",
        "        plt.show()\n",
        "\n",
        "def plot_confusion_matrix(y_true,y_pred,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True,\n",
        "                          figsize=(10, 8),\n",
        "                          digit_format='{:0.2f}',\n",
        "                          save_as='auto'):\n",
        "    \"\"\"\n",
        "    given a sklearn confusion matrix (cm), make a nice plot\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "\n",
        "    target_names: given classification classes such as [0, 1, 2]\n",
        "                  the class names, for example: ['high', 'medium', 'low']\n",
        "\n",
        "    title:        the text to display at the top of the matrix\n",
        "\n",
        "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                  plt.get_cmap('jet') or plt.cm.Blues\n",
        "\n",
        "    normalize:    If False, plot the raw numbers\n",
        "                  If True, plot the proportions\n",
        "\n",
        "    Citiation\n",
        "    ---------\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix( y_true,y_pred, normalize=None, labels=target_names)\n",
        "    \n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=90)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, digit_format.format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    \n",
        "def display_confusion_matrix(y_true,y_pred,labels=None,color='green',\n",
        "                             font_size='12pt'):\n",
        "    \"\"\"\n",
        "    Show a confusion matrix for a predictions.\n",
        "    see : sklearn.metrics.confusion_matrix\n",
        "\n",
        "    Args:\n",
        "        y_true:       Real classes\n",
        "        y_pred:       Predicted classes\n",
        "        labels:       List of classes to show in the cm\n",
        "        color:        Color for the palette (green)\n",
        "        font_size:    Values font size \n",
        "        title:        the text to display at the top of the matrix        \n",
        "    \"\"\"\n",
        "    assert (labels!=None),\"Label must be set\"\n",
        "    \n",
        "    \n",
        "    cm = confusion_matrix( y_true,y_pred, normalize=\"true\", labels=labels)\n",
        "    df=pd.DataFrame(cm)\n",
        "\n",
        "#     cmap = sn.light_palette(color, as_cmap=True)\n",
        "\n",
        "    colorsList = ['whitesmoke','bisque']\n",
        "    cmap = matplotlib.colors.ListedColormap(colorsList)\n",
        "    cmap = matplotlib.colors.ListedColormap(cmap(np.linspace(0, 1, 256)))\n",
        "\n",
        "    df.style.set_properties(**{'font-size': '20pt'})\n",
        "    display(df.style.format('{:.2f}') \\\n",
        "            .background_gradient(cmap=cmap)\n",
        "            .set_properties(**{'font-size': font_size}))\n",
        "    \n",
        "\n",
        "def plot_donut(values, labels, colors=[\"lightsteelblue\",\"coral\"], figsize=(6,6), title=None):\n",
        "    \"\"\"\n",
        "    Draw a donut\n",
        "    args:\n",
        "        values   : list of values\n",
        "        labels   : list of labels\n",
        "        colors   : list of color ([\"lightsteelblue\",\"coral\"])\n",
        "        figsize  : size of figure ( (6,6) )\n",
        "    return:\n",
        "        nothing\n",
        "    \"\"\"\n",
        "    # ---- Title or not\n",
        "    if title != None :  display(Markdown(title))\n",
        "    # ---- Donut\n",
        "    plt.figure(figsize=figsize)\n",
        "    # ---- Draw a pie  chart..\n",
        "    plt.pie(values, labels=labels, \n",
        "            colors = colors, autopct='%1.1f%%', startangle=70, pctdistance=0.85,\n",
        "            textprops={'fontsize': 18},\n",
        "            wedgeprops={\"edgecolor\":\"w\",'linewidth': 5, 'linestyle': 'solid', 'antialiased': True})\n",
        "    # ---- ..with a white circle\n",
        "    circle = plt.Circle((0,0),0.70,fc='white')\n",
        "    ax = plt.gca()\n",
        "    ax.add_artist(circle)\n",
        "    # Equal aspect ratio ensures that pie is drawn as a circle\n",
        "    plt.axis('equal')  \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def rmax(l):\n",
        "    \"\"\"\n",
        "    Recursive max() for a given iterable of iterables\n",
        "    Should be np.array of np.array or list of list, etc.\n",
        "    args:\n",
        "        l : Iterable of iterables\n",
        "    return: \n",
        "        max value\n",
        "    \"\"\"\n",
        "    maxi = float('-inf')\n",
        "    for item in l:\n",
        "        if isinstance(item, Iterable):\n",
        "\n",
        "            t = rmax(item)\n",
        "        else:\n",
        "            t = item\n",
        "        if t > maxi:\n",
        "            maxi = t\n",
        "    return maxi\n",
        "\n",
        "def rmin(l):\n",
        "    \"\"\"\n",
        "    Recursive min() for a given iterable of iterables\n",
        "    Should be np.array of np.array or list of list, etc.\n",
        "    args:\n",
        "        l : Iterable of iterables\n",
        "    return: \n",
        "        min value\n",
        "    \"\"\"\n",
        "    mini = float('inf')\n",
        "    for item in l:\n",
        "        if isinstance(item, Iterable):\n",
        "            t = rmin(item)\n",
        "        else:\n",
        "            t = item\n",
        "        if t < mini:\n",
        "            mini = t\n",
        "    return mini\n",
        "\n"
      ],
      "metadata": {
        "id": "3T93eFS01j1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-eq7McA0bYx"
      },
      "source": [
        "# <!-- TITLE --> [SYNOP1] - Preparation of data\n",
        "<!-- DESC --> Episode 1 : Data analysis and preparation of a usuable meteorological dataset (SYNOP)\n",
        "<!-- AUTHOR : Jean-Luc Parouty (CNRS/SIMaP) -->\n",
        "\n",
        "## Objectives :\n",
        " - Undestand the data\n",
        " - cleanup a usable dataset\n",
        "\n",
        "\n",
        "SYNOP meteorological data, can be found on :  \n",
        "https://public.opendatasoft.com  \n",
        "\n",
        "About SYNOP datasets :  \n",
        "https://public.opendatasoft.com/explore/dataset/donnees-synop-essentielles-omm/information/?sort=date\n",
        "\n",
        "This dataset contains a set of measurements (temperature, pressure, ...) made every 3 hours at the LYS airport.  \n",
        "The objective will be to predict the evolution of the weather !\n",
        "\n",
        "## What we're going to do :\n",
        "\n",
        " - Read the data\n",
        " - Cleanup and build a usable dataset\n",
        "\n",
        "## Step 1 - Import and init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY1ncfbO0bY4"
      },
      "source": [
        "## Step 2 - Parameters\n",
        "`output_dir` : where to save our enhanced dataset.  \n",
        "./data is a good choice because our dataset will be very small."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yX6azWdD0bY5"
      },
      "outputs": [],
      "source": [
        "# ---- Our future enhanced dataset (no need to change)\n",
        "#\n",
        "dataset_filename     = 'synop-LYS.csv'\n",
        "description_filename = 'synop.json'\n",
        "output_dir           = './data'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNBRkkU00bY7"
      },
      "source": [
        "## Step 3 - Retrieve the dataset\n",
        "There are two parts to recover:\n",
        " - The data itself (csv)\n",
        " - Description of the data (json)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEFMEHYF0bY8"
      },
      "outputs": [],
      "source": [
        "data_filename   = 'https://github.com/lsteffenel/CHPS0942/raw/main/SYNOP/donnees-synop-essentielles-omm-LYS.csv'\n",
        "schema_filename = 'https://github.com/lsteffenel/CHPS0942/raw/main/SYNOP/schema.json'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/lsteffenel/CHPS0942/raw/main/SYNOP/donnees-synop-essentielles-omm-LYS.csv"
      ],
      "metadata": {
        "id": "LpCCIV861DFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/lsteffenel/CHPS0942/raw/main/SYNOP/schema.json"
      ],
      "metadata": {
        "id": "0vWqej_T1HmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vJ2ZI810bY9"
      },
      "source": [
        "### 3.1 - Read dataset description\n",
        "We need the list and description of the columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pv5_IZtv0bY-"
      },
      "outputs": [],
      "source": [
        "with open(f'schema.json','r') as json_file:\n",
        "    schema = json.load(json_file)\n",
        "\n",
        "synop_codes=list( schema['definitions']['donnees-synop-essentielles-omm_records']['properties']['fields']['properties'].keys() )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIWuV2Hp0bY_"
      },
      "source": [
        "### 3.2 - Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t87reZGl0bY_"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(f'donnees-synop-essentielles-omm-LYS.csv', header=0, sep=';')\n",
        "print('Raw data :')\n",
        "display(df.tail(10))\n",
        "\n",
        "# ---- Get the columns name as descriptions\n",
        "synop_desc = list(df.columns)\n",
        "\n",
        "# ---- Set Codes as columns name\n",
        "df.columns   = synop_codes\n",
        "code2desc    = dict(zip(synop_codes, synop_desc))\n",
        "\n",
        "# ---- Count the na values by columns\n",
        "columns_na = df.isna().sum().tolist()\n",
        "\n",
        "# ---- Show all of that\n",
        "df_desc=pd.DataFrame({'Code':synop_codes, 'Description':synop_desc, 'Na':columns_na})\n",
        "\n",
        "print('List of columns :')\n",
        "display(df_desc.style.set_properties(**{'text-align': 'left'}))\n",
        "\n",
        "print('Shape is : ', df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_X3AxCmK0bZA"
      },
      "source": [
        "## Step 4 - Prepare dataset\n",
        "### 4.1 - Keep only certain columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWHrq5yy0bZA"
      },
      "outputs": [],
      "source": [
        "columns_used=['date','pmer','tend','cod_tend','dd','ff','td','u','ww','pres','rafper','per','rr1','rr3','tc']\n",
        "\n",
        "# ---- Drop unused columns\n",
        "\n",
        "to_drop = df.columns.difference(columns_used)\n",
        "df.drop( to_drop, axis=1, inplace=True)\n",
        "\n",
        "# ---- Show all of that\n",
        "\n",
        "print('Our selected columns :')\n",
        "display(df.head(20))\n",
        "\n",
        "print('Few statistics :')\n",
        "display(df.describe().style.format('{:.2f}'))\n",
        "\n",
        "# ---- 'per' column is constant, we can drop it\n",
        "\n",
        "df.drop(['per'],axis=1,inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO_I2iaW0bZB"
      },
      "source": [
        "### 4.2 - Cleanup dataset\n",
        "Let's sort it and cook up some NaN values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AI0kwpY00bZB"
      },
      "outputs": [],
      "source": [
        "# ---- First of all, we have to sort on the date\n",
        "\n",
        "df.sort_values(['date'],  inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# ---- Before : Lines with NaN\n",
        "\n",
        "na_rows=df.isna().any(axis=1)\n",
        "print('Before :')\n",
        "display( df[na_rows].head(10) )\n",
        "\n",
        "# ---- Nice interpolation for plugging holes\n",
        "\n",
        "df.interpolate(inplace=True)\n",
        "\n",
        "# ---- After\n",
        "\n",
        "print('After :')\n",
        "display(df[na_rows].head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqFFuXtY0bZC"
      },
      "source": [
        "## Step 5 - About our enhanced dataset\n",
        "### 5.1 - Summarize it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0cfUIV20bZC"
      },
      "outputs": [],
      "source": [
        "# ---- Count the na values by columns\n",
        "dataset_na    = df.isna().sum().tolist()\n",
        "dataset_cols  = df.columns.tolist()\n",
        "dataset_desc  = [ code2desc[c] for c in dataset_cols ]\n",
        "\n",
        "# ---- Show all of that\n",
        "df_desc=pd.DataFrame({'Columns':dataset_cols, 'Description':dataset_desc, 'Na':dataset_na})\n",
        "print('Dataset columns :')\n",
        "display(df_desc.style.set_properties(**{'text-align': 'left'}))\n",
        "\n",
        "print('Have a look :')\n",
        "display(df.tail(20))\n",
        "print('Shape is : ', df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4inXwhQe0bZC"
      },
      "source": [
        "### 5.2 - Have a look (1 month)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbnHzwEk0bZD"
      },
      "outputs": [],
      "source": [
        "i=random.randint(0,len(df)-240)\n",
        "df.iloc[i:i+240].plot(subplots=True, fontsize=12, figsize=(16,20))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDJjgLRk0bZD"
      },
      "source": [
        "## Step 6 - Save it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-1qL9qF0bZD"
      },
      "outputs": [],
      "source": [
        "# ---- Save it\n",
        "#\n",
        "os.makedirs(f'{output_dir}',   mode=0o750, exist_ok=True)\n",
        "\n",
        "filedata = f'{output_dir}/{dataset_filename}'\n",
        "filedesc = f'{output_dir}/{description_filename}'\n",
        "\n",
        "df.to_csv(filedata, sep=';', index=False)\n",
        "size=os.path.getsize(filedata)/(1024*1024)\n",
        "print(f'Dataset saved. ({size:0.1f} Mo)')\n",
        "\n",
        "with open(filedesc, 'w', encoding='utf-8') as f:\n",
        "    json.dump(code2desc, f, indent=4)\n",
        "print('Synop description saved.')\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we download the generated data files to your machine **(we will use them in the next notebooks)**"
      ],
      "metadata": {
        "id": "N32PiITj25t-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfukBxjQ0bZE"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('data/synop-LYS.csv')\n",
        "files.download('data/synop.json')"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "8e38643e33497db9a306e3f311fa98cb1e65371278ca73ee4ea0c76aa5a4f387"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('fidle-cpu': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "SYNOP1_Preparation_of_data.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}