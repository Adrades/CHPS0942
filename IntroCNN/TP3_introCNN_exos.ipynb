{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXuxp5CnX3CN"
      },
      "source": [
        "## Réseaux Fully Connected (Dense)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "RAckl7znX3CO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(tf.__version__)\n",
        "keras.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86xt_M3tX3CP"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAIfxwdeX3CS"
      },
      "outputs": [],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xp0Om0miX3CS"
      },
      "outputs": [],
      "source": [
        "im_train = x_train.reshape(60000,28,28)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ax5H5z-X3CS"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "plt.imshow((im_train[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4d4wrKZX3CS"
      },
      "outputs": [],
      "source": [
        "print(y_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiQCvWyNX3CT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(im_train[8], cmap=plt.cm.binary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6wkUukEX3CT"
      },
      "outputs": [],
      "source": [
        "print(y_train[8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkjau0gZX3CT"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "from numpy import linalg\n",
        "numpy.set_printoptions(precision=2, suppress=True, linewidth=120)\n",
        "print(numpy.matrix(im_train[8]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4F6PaA6PX3CU"
      },
      "outputs": [],
      "source": [
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGDkcJOiX3CU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5C_i3qPbX3CV"
      },
      "outputs": [],
      "source": [
        "print(y_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQyfiSJfX3CV"
      },
      "source": [
        "- L’objectif de cette seconde séance de travaux pratiques est de prendre en main la librairie Keras https://keras.io/ pour utiliser et entraîner des réseaux de neurones profonds.\n",
        "\n",
        "- Avec Keras, les réseaux de neurones avec une structure de chaîne (réseaux feedforward), s’utilisent de la manière suivante:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKg15jsiX3CV"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGDAemA5X3CV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# model = Sequential()   .... pour TF1\n",
        "model = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XqKheZDX3CV"
      },
      "source": [
        "- On crée ainsi un réseau de neurones vide. On peut alors ajouter des couches avec la fonction add."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onoP-80MX3CV"
      },
      "source": [
        "##  Régression Logistique avec Keras\n",
        "\n",
        "Par exemple, l’ajout d’une couche de projection linéaire (couche complètement connectée) de taille 10, suivi de l’ajout d’une couche d’activation de type softmax, peuvent s’effectuer de la manière suivante :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itMFXST3X3CW"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense, Activation\n",
        "\n",
        "model.add(tf.keras.layers.Dense(10 , activation='softmax',  input_dim=784 ))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lbp2RmpyX3CW"
      },
      "source": [
        "- On peut ensuite visualiser l’architecture du réseau avec la méthode summary() du modèle.\n",
        "\n",
        "#### Question :\n",
        "Vérifier le nombre de paramètres du réseau à apprendre dans la méthode summary(). \n",
        "Écrire un script permettant de créer le réseau de neurone ci-dessus.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUrKHqLLX3CW"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRJbuoSxX3CW"
      },
      "source": [
        "- Avec Keras, on va compiler le modèle en lui passant :\n",
        "    - un loss (ici l’entropie croisée) ;\n",
        "    - une méthode d’optimisation (ici une descente de gradient stochastique, stochastic gradient descent, sgd) ; \n",
        "    - une métrique d’évaluation (ici le taux de bonne prédiction des catégories, accuracy)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJsjfQZBX3CW"
      },
      "outputs": [],
      "source": [
        "#from keras.optimizers import SGD    : TF1\n",
        "from tensorflow.keras.optimizers import SGD   # TF2\n",
        "\n",
        "opt = SGD(learning_rate=0.1)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer= opt, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfmKAVetX3CW"
      },
      "source": [
        "Enfin, l’apprentissage du modèle sur des données d’apprentissage est mis en place avec la méthode fit :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_92MPVrmX3CW"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.fit(x_train, y_train, batch_size=50, epochs=5,verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZxl9JVbX3CX"
      },
      "source": [
        "- batch_size correspond au nombre d’exemples utilisé pour estimer le gradient de la fonction de coût.\n",
        "- epochs est le nombre d’époques (i.e. passages sur l’ensemble des exemples de la base d’apprentissage) lors de la descente de gradient.\n",
        "\n",
        "- N.B : on rappelle que les étiquettes (labels) données par la supervision doivent être au format one-hot encoding.\n",
        "\n",
        "On peut ensuite évaluer les performances du modèle sur l’ensemble de test avec la fonction evaluate :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYmpAx7pX3CX"
      },
      "outputs": [],
      "source": [
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[0], scores[0]*100))\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFMP5ZbaX3CX"
      },
      "source": [
        "Le premier élément de scores renvoie la fonction de coût sur la base de test, le second élément renvoie le taux de bonne détection (accuracy)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zviq3ce7X3CX"
      },
      "source": [
        "### Sauvegader un modèle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKZFhh3hX3CX"
      },
      "source": [
        "\n",
        " \n",
        " On pourra utiliser la méthode suivante pour sauvegarder le modèle appris :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yK7kuRJX3CX"
      },
      "outputs": [],
      "source": [
        "from keras.models import model_from_yaml\n",
        "def saveModel(model, savename):\n",
        "    # serialize model to YAML\n",
        "    model_yaml = model.to_yaml()\n",
        "    with open(savename+\".yaml\", \"w\") as yaml_file:\n",
        "        yaml_file.write(model_yaml)\n",
        "        print(\"Yaml Model \",savename,\".yaml saved to disk\")\n",
        "    # serialize weights to HDF5\n",
        "    model.save_weights(savename+\".h5\")\n",
        "    print(\"Weights \",savename,\".h5 saved to disk\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dyavw_uX3CY"
      },
      "source": [
        "### Essayer d'autres modèles en changeant les hyper-paramètres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sm1P_hRqX3CY"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKrOhsh7X3CY"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(10, activation='sigmoid', input_dim =(784)))#input_shape(784,)\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "# Déclaration du modèle Tensorflow 1.?\n",
        "#model = Sequential()\n",
        "#model.add(Dense(10, activation='sigmoid', input_shape=(784,)))\n",
        "#model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# résumé du modèle\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RT8uKuHLX3CY"
      },
      "outputs": [],
      "source": [
        "batch_size = 50\n",
        "num_classes = 10\n",
        "epochs=10\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='SGD',  metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,  batch_size=batch_size, epochs=epochs, verbose=1 )\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKi0oOGuX3CY"
      },
      "source": [
        "### activation function : relu + new hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tB69iYUkX3CY"
      },
      "outputs": [],
      "source": [
        "batch_size = 50\n",
        "num_classes = 10\n",
        "epochs=10\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu', input_dim =(784)))#input_shape(784,)\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='SGD',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1\n",
        "          )\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose =0)\n",
        "\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9gvQiQ2X3CY"
      },
      "source": [
        "## Réseaux de neurones convolutifs avec Keras\n",
        "\n",
        "On va maintenant étendre le perceptron de l’exercice précédent pour mettre en place un réseau de neurones convolutif profond, Convolutional Neural Networks, ConvNets.\n",
        "\n",
        "Écrire un script pour mettre en place un ConvNet.\n",
        "\n",
        "Les réseaux convolutifs manipulent des images multi-dimensionnelles en entrée (tenseurs). On va donc commencer par reformater les données d’entrée afin que chaque exemple soit de taille 28×28×1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSOWk0NAX3CY"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70wr-cNkX3CZ"
      },
      "source": [
        "Par rapport aux réseaux complètement connectés, les réseaux convolutifs utilisent les briques élémentaires suivantes :\n",
        "\n",
        "   1. Des couches de convolution, qui transforment un tenseur d’entrée de taille nx×ny×p\n",
        "\n",
        "en un tenseur de sortie nx′×ny′×nH, où nH est le nombre de filtres choisi.\n",
        "\n",
        "Par exemple, une couche de convolution pour traiter les images d’entrée de MNIST peut être créée de la manière suivante :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NvB6Y3bX3CZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "conv=Conv2D(32,kernel_size=(5, 5),activation='sigmoid',input_shape=(28, 28, 1),padding='same')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klNPO4CAX3CZ"
      },
      "source": [
        "    - 32 : nombre de filtres.\n",
        "    - (5, 5) : taille spatiale de chaque filtre (masque de convolution).\n",
        "    - padding='same' correspond à garder la même taille spatiale en sortie de la convolution.\n",
        "    \n",
        "    N.B. : on peut directement inclure dans la couche de convolution la non-linéarité en sortie de la convolution, comme illustré ici dans l’exemple avec une fonction d’activation de type sigmoid.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  2. Des couches d’agrégation spatiale (pooling), afin de permettre une invariance aux translations locales. Voici par exemple la manière de déclarer une couche de max-pooling:\n"
      ],
      "metadata": {
        "id": "BIM-ISTDSuga"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnZW6F7SX3CZ"
      },
      "outputs": [],
      "source": [
        "pool = MaxPooling2D(pool_size=(2, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfCSlMoQX3CZ"
      },
      "source": [
        "    (2, 2) : la taille spatiale sur laquelle l’opération d’agrégation est effectuée.\n",
        "    N.B. : par défaut, le pooling est effectué avec un décalage de 2 neurones, dans l’exemple précédent on obtient donc des cartes de sorties avec des tailles spatiales divisées par deux par rapport à la taille d’entrée.\n",
        "\n",
        "### Exercice : \n",
        "Compléter le script pour mettre en place un ConvNet à l’architecture suivante, proche du modèle historique LeNet5 [LBD+89] et montré ci-dessous:\n",
        "\n",
        "        - Une couche de convolution avec 32 filtres de taille 5×5, suivie d’une non linéarité de type sigmoïde  puis d’une couche de max pooling de taille 2×2.\n",
        "        - Une seconde couche de convolution avec 64 filtres de taille 5×5, suivie d’une non linéarité de type sigmoïde puis d’une couche de max pooling de taille 2×2.\n",
        "        - Comme dans le réseau LeNet, on considérera la sortie du second bloc convolutif comme un vecteur, ce que revient à « mettre à plat » les couches convolutives précédentes (model.add(Flatten())).\n",
        "        - Une couche complètement connectée de taille 100, suivie d’une non linéarité de type sigmoïde.\n",
        "        - Une couche complètement connectée de taille 10, suivie d’une non linéarité de type softmax."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(conv)\n",
        "### le reste est à vous de compléter\n"
      ],
      "metadata": {
        "id": "jcIw7N2CTBuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "QtX_i0v_Sxr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jihaW7C2X3CZ"
      },
      "source": [
        "\n",
        "    - Apprendre le modèle et évaluer les performances du réseau sur la base de test. Vous devez obtenir un score de l’ordre de 97% pour ce modèle ConvNet.\n",
        "    - Quelle est le temps d’une époque avec ce modèle convolutif ?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZXQrBJ1X3CZ"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='SGD',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1\n",
        "          )\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose =0)\n",
        "\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ziWUqSQRT3sD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "TP2_introCNN_exos (1).ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}